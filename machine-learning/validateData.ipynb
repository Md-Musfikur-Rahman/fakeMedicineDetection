{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Lambda, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Load and Preprocess the Dataset\n",
    "df = pd.read_csv('/kaggle/input/spectra/Spectra_Data.csv', index_col=0)\n",
    "labels = df.iloc[:, -1].values\n",
    "features = df.iloc[:, :-1].values\n",
    "\n",
    "# Convert labels to integers\n",
    "labels = labels.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Balance the Dataset if Necessary\n",
    "class_counts = np.bincount(labels)\n",
    "min_class_count = np.min(class_counts)\n",
    "if min_class_count < 50:  # Threshold for minimum samples per class\n",
    "    indices = np.where(labels == np.argmin(class_counts))[0]\n",
    "    extra_samples = indices[:len(indices) - min_class_count]\n",
    "    X_train_balanced = np.vstack((X_train, X_train[extra_samples]))\n",
    "    y_train_balanced = np.concatenate((y_train, y_train[extra_samples]))\n",
    "else:\n",
    "    X_train_balanced = X_train\n",
    "    y_train_balanced = y_train\n",
    "\n",
    "# Reshape input data\n",
    "X_train_balanced = X_train_balanced.reshape(-1, X_train_balanced.shape[1], 1)\n",
    "X_test = X_test.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "# Feature Extraction with 1D CNN\n",
    "def create_cnn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Conv1D(128, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Added dropout\n",
    "    x = BatchNormalization()(x)  # Added batch normalization\n",
    "    return Model(inputs, x)\n",
    "\n",
    "input_shape = (X_train_balanced.shape[1], 1)\n",
    "feature_extractor = create_cnn_model(input_shape)\n",
    "feature_extractor.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Siamese Neural Network for Classification\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def create_siamese_network(feature_extractor):\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    processed_a = feature_extractor(input_a)\n",
    "    processed_b = feature_extractor(input_b)\n",
    "    distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "    return Model([input_a, input_b], distance)\n",
    "\n",
    "siamese_network = create_siamese_network(feature_extractor)\n",
    "\n",
    "# Custom loss function with adjusted margin\n",
    "def contrastive_loss(y_true, y_pred, margin=1.5):\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "siamese_network.compile(optimizer=RMSprop(learning_rate=0.001), loss=contrastive_loss)\n",
    "\n",
    "# Generate Pairs and Train the Siamese Network\n",
    "def generate_pairs(X, y, num_positives=100, num_negatives=100):\n",
    "    pos_pairs = []\n",
    "    neg_pairs = []\n",
    "    for _ in range(num_positives):\n",
    "        pos_indices = np.where(y == 0)[0]\n",
    "        if len(pos_indices) > 1:\n",
    "            pair_idx = np.random.choice(pos_indices, size=2, replace=False)\n",
    "            pos_pairs.append((pair_idx[0], pair_idx[1]))\n",
    "   \n",
    "    for _ in range(num_negatives):\n",
    "        neg_indices = np.where(y == 1)[0]\n",
    "        if len(neg_indices) > 1:\n",
    "            pair_idx = np.random.choice(neg_indices, size=2, replace=False)\n",
    "            neg_pairs.append((pair_idx[0], pair_idx[1]))\n",
    "   \n",
    "    return np.array(pos_pairs), np.array(neg_pairs)\n",
    "\n",
    "pos_pairs, neg_pairs = generate_pairs(np.arange(len(y_train_balanced)), y_train_balanced)\n",
    "\n",
    "# Check if any pairs were generated\n",
    "if len(pos_pairs) == 0 or len(neg_pairs) == 0:\n",
    "    raise ValueError(\"Insufficient samples for training.\")\n",
    "\n",
    "# Prepare the pairs and labels\n",
    "X_pos_pairs = [X_train_balanced[pos_pairs[:, 0]], X_train_balanced[pos_pairs[:, 1]]]\n",
    "X_neg_pairs = [X_train_balanced[neg_pairs[:, 0]], X_train_balanced[neg_pairs[:, 1]]]\n",
    "\n",
    "X_a = np.concatenate([X_pos_pairs[0], X_neg_pairs[0]], axis=0)\n",
    "X_b = np.concatenate([X_pos_pairs[1], X_neg_pairs[1]], axis=0)\n",
    "y_pairs = np.concatenate([np.ones(len(pos_pairs)), np.zeros(len(neg_pairs))])\n",
    "\n",
    "siamese_network.fit([X_a, X_b], y_pairs, epochs=50, batch_size=64)  # Increased number of epochs\n",
    "\n",
    "# Evaluate the Model\n",
    "threshold = 1.0  # Adjust based on your dataset\n",
    "predictions = []\n",
    "for i in range(0, len(X_test)-1, 2):  # Assuming pairs in the test set\n",
    "    distance = siamese_network.predict([X_test[i:i+1], X_test[i+1:i+2]])\n",
    "    predictions.append(distance < threshold)\n",
    "\n",
    "accuracy = np.mean(predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
